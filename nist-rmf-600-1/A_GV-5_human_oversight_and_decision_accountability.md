---
title: Human Oversight and Decision Accountability
nist_function: Govern
priority_phase: Must
last_reviewed: 2025-06-24
status: draft
---

## Purpose

To ensure human-in-the-loop decision authority is preserved in all clinical or operational decisions influenced or generated by GenAI systems.

## Scope

Covers all GenAI systems supporting documentation, diagnostics, triage, administrative routing, or care recommendations in patient-facing or safety-relevant contexts.

## Policy Statement

GenAI systems must augment—not replace—human decision-making. Accountable individuals must review outputs, validate appropriateness, and retain authority for high-impact actions or recommendations.

## Roles and Responsibilities

- **Clinical Leads**: Review GenAI outputs in patient charts, diagnoses, and orders.
- **Workflow Designers**: Ensure GenAI systems flag uncertain or high-risk content.
- **AI Ethics Board**: Monitor automation bias, deskilling, and decision displacement trends.

## Implementation Phases

### Must Do
- Require human sign-off for GenAI-driven content used in patient records or billing (AI RMF GOVERN-5.2).
- Flag AI-generated content in user interfaces (AI 600-1 §2.4.1).
- Provide override and feedback tools for clinical staff.

### Should Do
- Conduct audits on human review compliance for high-risk decisions.
- Provide training on automation bias and prompt-risk awareness.
- Design decision pathways with fallbacks and escalation triggers.

### Recommended
- Monitor reviewer agreement rates and flag excessive overrides.
- Establish accountability registries linking AI suggestions to human approvers.
- Log user feedback to improve model alignment and trustworthiness.
